{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b62a65f-7272-4bb4-99c1-c2e0f00fb214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2579a5a7-ac7a-423e-ae5d-f49f8c5e18f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IRAN MAKES MAJOR Announcement About How They P...</td>\n",
       "      <td>fake</td>\n",
       "      <td>kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Britain seeks new ways to detect explosives in...</td>\n",
       "      <td>real</td>\n",
       "      <td>kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fox News Host Calls GOP Out On Voter ID Laws ...</td>\n",
       "      <td>fake</td>\n",
       "      <td>kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUSTRIAN JUSTICE SYSTEM Gives Teen With Homema...</td>\n",
       "      <td>fake</td>\n",
       "      <td>kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What Katy Perry Did With This Gift John Mayer ...</td>\n",
       "      <td>fake</td>\n",
       "      <td>gossipcop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label     source\n",
       "0  IRAN MAKES MAJOR Announcement About How They P...  fake     kaggle\n",
       "1  Britain seeks new ways to detect explosives in...  real     kaggle\n",
       "2   Fox News Host Calls GOP Out On Voter ID Laws ...  fake     kaggle\n",
       "3  AUSTRIAN JUSTICE SYSTEM Gives Teen With Homema...  fake     kaggle\n",
       "4  What Katy Perry Did With This Gift John Mayer ...  fake  gossipcop"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/processed/combined_fake_news_dataset.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db482707-f09c-41d8-86e3-f581c1a71a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df[\"text_clean\"] = df[\"text\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf1b8d91-4ddf-4382-a74d-0a666ae0483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df[\"text_clean\"])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df[\"text_clean\"])\n",
    "padded = pad_sequences(sequences, maxlen=300, padding='post', truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e04b7fb7-6d1b-4942-9157-ba7052c1c005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels = df[\"label\"].map({\"real\": 0, \"fake\": 1}).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    padded, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fc6b105-69e5-4dd7-b55c-1563b8a40e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\fakenews_env\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 309ms/step - accuracy: 0.8654 - loss: 0.2700 - val_accuracy: 0.9585 - val_loss: 0.1006\n",
      "Epoch 2/5\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 296ms/step - accuracy: 0.9696 - loss: 0.0760 - val_accuracy: 0.9557 - val_loss: 0.1062\n",
      "Epoch 3/5\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 279ms/step - accuracy: 0.9775 - loss: 0.0561 - val_accuracy: 0.9565 - val_loss: 0.1156\n",
      "Epoch 4/5\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 300ms/step - accuracy: 0.9879 - loss: 0.0319 - val_accuracy: 0.9545 - val_loss: 0.1740\n",
      "Epoch 5/5\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 280ms/step - accuracy: 0.9923 - loss: 0.0192 - val_accuracy: 0.9509 - val_loss: 0.1842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c910ebcaf0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "\n",
    "model_lstm = Sequential([\n",
    "    Embedding(10000, 64, input_length=300),\n",
    "    Bidirectional(LSTM(64)),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_lstm.fit(X_train, y_train, validation_split=0.2, epochs=5, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e953579-907e-45fa-b86e-e81d36602172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 81ms/step - accuracy: 0.8383 - loss: 0.3182 - val_accuracy: 0.9565 - val_loss: 0.1090\n",
      "Epoch 2/5\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 83ms/step - accuracy: 0.9674 - loss: 0.0867 - val_accuracy: 0.9604 - val_loss: 0.0967\n",
      "Epoch 3/5\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 80ms/step - accuracy: 0.9844 - loss: 0.0463 - val_accuracy: 0.9581 - val_loss: 0.1097\n",
      "Epoch 4/5\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 80ms/step - accuracy: 0.9952 - loss: 0.0167 - val_accuracy: 0.9496 - val_loss: 0.1657\n",
      "Epoch 5/5\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 84ms/step - accuracy: 0.9992 - loss: 0.0042 - val_accuracy: 0.9497 - val_loss: 0.1874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c92a1a18a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "model_cnn = Sequential([\n",
    "    Embedding(10000, 64, input_length=300),\n",
    "    Conv1D(128, 5, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_cnn.fit(X_train, y_train, validation_split=0.2, epochs=5, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b151cc36-00c9-4faf-865d-7618db71212c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 174ms/step - accuracy: 0.6922 - loss: 0.5633 - val_accuracy: 0.8831 - val_loss: 0.3557\n",
      "Epoch 2/5\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 175ms/step - accuracy: 0.8749 - loss: 0.3572 - val_accuracy: 0.9044 - val_loss: 0.2737\n",
      "Epoch 3/5\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 176ms/step - accuracy: 0.8505 - loss: 0.3461 - val_accuracy: 0.9174 - val_loss: 0.2023\n",
      "Epoch 4/5\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 176ms/step - accuracy: 0.9168 - loss: 0.1862 - val_accuracy: 0.9212 - val_loss: 0.2337\n",
      "Epoch 5/5\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 176ms/step - accuracy: 0.9385 - loss: 0.1511 - val_accuracy: 0.9208 - val_loss: 0.1674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c952375c30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GRU\n",
    "\n",
    "model_gru = Sequential([\n",
    "    Embedding(10000, 64, input_length=300),\n",
    "    GRU(64),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_gru.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_gru.fit(X_train, y_train, validation_split=0.2, epochs=5, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dfd467b-1d65-4693-b112-277086928e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 54ms/step\n",
      "=== BiLSTM ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      5750\n",
      "           1       0.95      0.96      0.95      5206\n",
      "\n",
      "    accuracy                           0.96     10956\n",
      "   macro avg       0.96      0.96      0.96     10956\n",
      "weighted avg       0.96      0.96      0.96     10956\n",
      "\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
      "=== CNN ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      5750\n",
      "           1       0.94      0.97      0.95      5206\n",
      "\n",
      "    accuracy                           0.95     10956\n",
      "   macro avg       0.95      0.95      0.95     10956\n",
      "weighted avg       0.95      0.95      0.95     10956\n",
      "\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 42ms/step\n",
      "=== GRU ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92      5750\n",
      "           1       0.88      0.96      0.92      5206\n",
      "\n",
      "    accuracy                           0.92     10956\n",
      "   macro avg       0.92      0.92      0.92     10956\n",
      "weighted avg       0.92      0.92      0.92     10956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate(model, name):\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "evaluate(model_lstm, \"BiLSTM\")\n",
    "evaluate(model_cnn, \"CNN\")\n",
    "evaluate(model_gru, \"GRU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c7166a4-d554-4e47-9ad7-a9aad730da01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 46ms/step\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
      "=== Ensemble (BiLSTM + CNN) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      5750\n",
      "           1       0.95      0.97      0.96      5206\n",
      "\n",
      "    accuracy                           0.96     10956\n",
      "   macro avg       0.96      0.96      0.96     10956\n",
      "weighted avg       0.96      0.96      0.96     10956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Get predictions (probabilities) from both models\n",
    "bilstm_probs = model_lstm.predict(X_test)\n",
    "cnn_probs = model_cnn.predict(X_test)\n",
    "\n",
    "# 2. Average the predicted probabilities (soft voting)\n",
    "ensemble_probs = (bilstm_probs + cnn_probs) / 2\n",
    "\n",
    "# 3. Convert probabilities to final class predictions\n",
    "ensemble_preds = (ensemble_probs > 0.5).astype(int)\n",
    "\n",
    "# 4. Evaluate ensemble performance\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"=== Ensemble (BiLSTM + CNN) ===\")\n",
    "print(classification_report(y_test, ensemble_preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "217b161b-cd31-4dbe-b90a-60c10be41c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model_lstm.save(\"models/bilstm_model.h5\")\n",
    "model_cnn.save(\"models/cnn_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ebd189-5993-47d8-abba-bd91b677794f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (FakeNewsEnv)",
   "language": "python",
   "name": "fakenews_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
