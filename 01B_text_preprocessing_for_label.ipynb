{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94b3d731-84e4-46a2-a83f-95e6a113b609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb96a3dc-3ed1-48c2-9e01-6eed775376cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IRAN MAKES MAJOR Announcement About How They P...</td>\n",
       "      <td>fake</td>\n",
       "      <td>kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Britain seeks new ways to detect explosives in...</td>\n",
       "      <td>real</td>\n",
       "      <td>kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fox News Host Calls GOP Out On Voter ID Laws ...</td>\n",
       "      <td>fake</td>\n",
       "      <td>kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUSTRIAN JUSTICE SYSTEM Gives Teen With Homema...</td>\n",
       "      <td>fake</td>\n",
       "      <td>kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What Katy Perry Did With This Gift John Mayer ...</td>\n",
       "      <td>fake</td>\n",
       "      <td>gossipcop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54772</th>\n",
       "      <td>Trump’s Muslim Ban Has One MAJOR Cheerleader ...</td>\n",
       "      <td>fake</td>\n",
       "      <td>kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54773</th>\n",
       "      <td>Why The Death Of Justice Scalia Makes The Sup...</td>\n",
       "      <td>fake</td>\n",
       "      <td>kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54774</th>\n",
       "      <td>EU's Tusk cancels Mideast trip due to Brexit c...</td>\n",
       "      <td>real</td>\n",
       "      <td>kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54775</th>\n",
       "      <td>Elle King skips out on her own wedding. Elle K...</td>\n",
       "      <td>real</td>\n",
       "      <td>gossipcop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54776</th>\n",
       "      <td>BRONX HOSPITAL SHOOTING: Multiple People Shot,...</td>\n",
       "      <td>fake</td>\n",
       "      <td>kaggle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54777 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text label     source\n",
       "0      IRAN MAKES MAJOR Announcement About How They P...  fake     kaggle\n",
       "1      Britain seeks new ways to detect explosives in...  real     kaggle\n",
       "2       Fox News Host Calls GOP Out On Voter ID Laws ...  fake     kaggle\n",
       "3      AUSTRIAN JUSTICE SYSTEM Gives Teen With Homema...  fake     kaggle\n",
       "4      What Katy Perry Did With This Gift John Mayer ...  fake  gossipcop\n",
       "...                                                  ...   ...        ...\n",
       "54772   Trump’s Muslim Ban Has One MAJOR Cheerleader ...  fake     kaggle\n",
       "54773   Why The Death Of Justice Scalia Makes The Sup...  fake     kaggle\n",
       "54774  EU's Tusk cancels Mideast trip due to Brexit c...  real     kaggle\n",
       "54775  Elle King skips out on her own wedding. Elle K...  real  gossipcop\n",
       "54776  BRONX HOSPITAL SHOOTING: Multiple People Shot,...  fake     kaggle\n",
       "\n",
       "[54777 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/processed/combined_fake_news_dataset.csv\") \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb92d4ba-13f1-4de2-95fa-25eab58bd0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text).lower()                        # lowercase\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)             # remove URLs\n",
    "    text = re.sub(r\"\\d+\", \"\", text)                 # remove digits\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)             # remove punctuation\n",
    "    return text\n",
    "\n",
    "data[\"text_clean\"] = data[\"text\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "891a25e1-364c-46a2-bad8-f2cf99a15daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0006878a-6fc2-49f1-9968-f1e9814c1dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "  import spacy\n",
    "\n",
    "# Load the small English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88b39e86-c297-4666-bb86-fed14c95311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenize_and_remove_stopwords(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454847bb-e430-4175-8e8a-e09f939ac3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text_tokens\"] = data[\"text_clean\"].apply(spacy_tokenize_and_remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf237dbb-506b-433d-83b3-d44caf4a6e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(data[\"text_tokens\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "596de17c-9ebc-4a7e-99f8-23dea29a9a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/source_label_encoder.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Map labels manually if needed (though LabelEncoder does this automatically)\n",
    "y = data[\"label\"].map({\"real\": 0, \"fake\": 1}) \n",
    "\n",
    "# Create and fit LabelEncoder\n",
    "le_label = LabelEncoder()\n",
    "le_label.fit([\"real\", \"fake\"])  # Fitting the encoder\n",
    "\n",
    "# ✅ Save the fitted encoder\n",
    "joblib.dump(le_label, \"models/source_label_encoder.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8d0e56-fe0d-4b04-8d5c-a46c0f984ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X.toarray()).to_csv(\"data/processed/vectorized_text.csv\", index=False)\n",
    "pd.DataFrame(y).to_csv(\"data/processed/labels.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (FakeNewsEnv)",
   "language": "python",
   "name": "fakenews_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
